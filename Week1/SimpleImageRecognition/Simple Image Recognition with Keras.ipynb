{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Classifying images using Keras  \n",
    "## @ AISaturdays Singapore\n",
    "####  By Nasrudin Salim\n",
    "https://github.com/Nasdin/AISaturdayTutorials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Image classifications of Dogs and Cats\n",
    "#### Creating a state-of-the-art image detection model for any category\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Downloading the dataset of your choice\n",
    "For this example, I would use the dogs and cats dataset provided here\n",
    "http://files.fast.ai/files/dogscats.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Please download and extract to /data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "    Separating Dataset into trend, test, validate\n",
    "    60% into train\n",
    "    20% into test\n",
    "    20% into validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#Locations of data files\n",
    "#These are variables depending on where you saved your data to\n",
    "#normally it's train and test (training is verified with test) \n",
    "#however the data came with train and validate followed by test being the verification, so we will just stick to that\n",
    "\n",
    "testpath = 'data/test1/'\n",
    "trainpath = 'data/train/'\n",
    "validpath = 'data/valid/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Note that the train and valid folders have subfolders\n",
    "\n",
    "    data/train\n",
    "    --> /cats/\n",
    "    --> /dogs/\n",
    "    data/valid\n",
    "    --> /cats/\n",
    "    --> /dogs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Creating the models with a pretrained Architecture\n",
    "We will use the ResNet50 architecture with pretrained weights from imagenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/nasdin/anaconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Instantiate the class model ResNet50, \"model\" with pretrained weights from imagenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
      "102129664/102853048 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "model = keras.applications.resnet50.ResNet50(include_top=True, weights='imagenet', \n",
    "                                     input_tensor=None, input_shape=None, pooling=None, classes=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Testing the imagenet model\n",
    "\n",
    "Create a function to feed from the directory of the images to make feeding of images easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "\n",
    "def get_batches(full_directory, shuffle=True, batch_size=4, class_mode='categorical',\n",
    "                target_size=(224,224)):\n",
    "    '''Retrieves images from a directory into batches ready to be trained with'''\n",
    "    \n",
    "    \n",
    "    #The Image Generator object which can be optimized\n",
    "    ImageGenerator = image.ImageDataGenerator()\n",
    "    #The method to retrieve batches of images\n",
    "    batches = ImageGenerator.flow_from_directory(\n",
    "        full_directory,\n",
    "        shuffle=shuffle,\n",
    "        batch_size=batch_size,\n",
    "        class_mode = class_mode,\n",
    "        target_size = target_size )\n",
    "    \n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  4.11039345e-08,   5.83101460e-08,   2.81110118e-07, ...,\n",
       "          1.05117941e-07,   2.24899268e-05,   5.93605546e-06],\n",
       "       [  1.14940057e-09,   1.26407010e-10,   3.02300748e-07, ...,\n",
       "          3.45268858e-09,   3.12956594e-09,   1.63710795e-10],\n",
       "       [  1.76446136e-07,   1.83243341e-08,   4.58474206e-05, ...,\n",
       "          1.74235367e-07,   1.38845010e-07,   9.70105816e-07],\n",
       "       [  3.46321940e-05,   8.00564885e-05,   3.69185873e-05, ...,\n",
       "          2.41499401e-06,   3.90111345e-05,   5.56927989e-05]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Get Batches from the train and validate directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batches_train = get_batches('data/train')\n",
    "batches_validate = get_batches('data/valid')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Predicting some samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def pred_batch(imgs,model=model):\n",
    "    ''' Input a batch of images with a model\n",
    "   '''\n",
    "    \n",
    "    preds = model.predict(imgs)\n",
    "    idxs = np.argmax(preds, axis=1)\n",
    "\n",
    "    print('Predictions prob/class: ')\n",
    "    \n",
    "    for i in range(len(idxs)):\n",
    "        idx = idxs[i]\n",
    "        print (idx)\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "img,labels=next(batches_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (4, 1000)\n",
      "First 5 probabilities: [  8.81620679e-07   1.72847535e-06   2.78921050e-07   8.84970859e-07\n",
      "   3.37605115e-06]\n",
      "\n",
      "Predictions prob/class: \n",
      "285\n",
      "233\n",
      "250\n",
      "178\n"
     ]
    }
   ],
   "source": [
    "pred_batch(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Working with Transfer Learning to add new categories (WIP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Create a function to retrieve images from the sub directory belonging to a category( dog or cat, etc)\n",
    "\n",
    "    Input a model to be trained\n",
    "    Inputs name of subdirectory (cat or dog, etc)\n",
    "    \n",
    "    1.Gets the full train and validate path of category\n",
    "    2.Trains the model\n",
    "    3.Output trained model\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def TrainModel(Category_subdirectory,model):\n",
    "    \n",
    "    #location of the category's train and validation files\n",
    "    train = trainpath + Category_subdirectory\n",
    "    validate = validpath + Category_subdirectory\n",
    "    #Batches of train images\n",
    "    train_image_batches = get_batches(train,batch_size=8)\n",
    "    validate_image_batches = get_batches(validate,batch_size=8)\n",
    "    \n",
    "    #Making changes to the last layer of the model's CNN\n",
    "    \n",
    "    pass\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
